{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/somefunagba/ias/ia2\n"
     ]
    }
   ],
   "source": [
    "from src.infer_models import infer\n",
    "from src.preprocess import preprocess\n",
    "from src.archs_models import stdlogistic\n",
    "from src.opts_models import batchgd\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from numpy.core.shape_base import block\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": [\"Computer Modern Sans Serif\"]})  # Avant Garde, Helvetica, Computer Modern Sans Serif\n",
    "# for Palatino and other serif fonts use:\n",
    "# plt.rcParams.update({\n",
    "#     \"text.usetex\": True,\n",
    "#     \"font.family\": \"serif\",\n",
    "#     \"font.serif\": [\"Computer Modern Roman\"], # Times, Bookman, Pa;atino\n",
    "# })\n",
    "# plt.rcParams.update({\n",
    "#     \"text.usetex\": True,\n",
    "#     \"font.family\": \"monospace\",\n",
    "#     \"font.monospace\": [\"Consolas\"],\n",
    "# })\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(formatter={'float': \"{:0.4f}\".format})\n",
    "\n",
    "\n",
    "# Ensure path is referenced to this script's root\n",
    "# thisdir = os.path.dirname(__file__)\n",
    "thisdir = Path.cwd()\n",
    "# os.chdir(thisdir)\n",
    "os.chdir(sys.path[0])\n",
    "print(os.getcwd())\n",
    "\n",
    "figs_dir = os.path.join(thisdir, 'figs/')\n",
    "if not os.path.isdir(figs_dir):\n",
    "    os.makedirs(figs_dir)\n",
    "\n",
    "# os.chdir(r'./ai534ias/ia1/')\n",
    "\n",
    "# Generate the path to the file relative to your python script:\n",
    "# script_location = Path(__file__).absolute().parent\n",
    "# print(script_location)\n",
    "# file_location = script_location / 'file.yaml'\n",
    "# file = file_location.open()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size (rows,columns) (16000, 198)\n",
      "                    Vehicle_Damage  Previously_Insured  Vehicle_Age_0  \\\n",
      "Vehicle_Damage            1.000000           -0.855336       0.309945   \n",
      "Previously_Insured       -0.855336            1.000000      -0.309128   \n",
      "Vehicle_Age_0             0.309945           -0.309128       1.000000   \n",
      "Vehicle_Age_1            -0.420687            0.412486      -0.859129   \n",
      "Vehicle_Age_2             0.177374           -0.163885      -0.342348   \n",
      "Response                  0.599459           -0.587338       0.257524   \n",
      "\n",
      "                    Vehicle_Age_1  Vehicle_Age_2  Response  \n",
      "Vehicle_Damage          -0.420687       0.177374  0.599459  \n",
      "Previously_Insured       0.412486      -0.163885 -0.587338  \n",
      "Vehicle_Age_0           -0.859129      -0.342348  0.257524  \n",
      "Vehicle_Age_1            1.000000      -0.186714 -0.342083  \n",
      "Vehicle_Age_2           -0.186714       1.000000  0.133690  \n",
      "Response                -0.342083       0.133690  1.000000  \n",
      "\n",
      "data size (rows,columns) (10000, 198)\n",
      "                    Vehicle_Damage  Previously_Insured  Vehicle_Age_0  \\\n",
      "Vehicle_Damage            1.000000           -0.853494       0.312304   \n",
      "Previously_Insured       -0.853494            1.000000      -0.306650   \n",
      "Vehicle_Age_0             0.312304           -0.306650       1.000000   \n",
      "Vehicle_Age_1            -0.421954            0.408671      -0.861005   \n",
      "Vehicle_Age_2             0.177401           -0.163749      -0.338647   \n",
      "Response                  0.600201           -0.589598       0.258971   \n",
      "\n",
      "                    Vehicle_Age_1  Vehicle_Age_2  Response  \n",
      "Vehicle_Damage          -0.421954       0.177401  0.600201  \n",
      "Previously_Insured       0.408671      -0.163749 -0.589598  \n",
      "Vehicle_Age_0           -0.861005      -0.338647  0.258971  \n",
      "Vehicle_Age_1            1.000000      -0.186967 -0.342723  \n",
      "Vehicle_Age_2           -0.186967       1.000000  0.133836  \n",
      "Response                -0.342723       0.133836  1.000000  \n",
      "\n",
      "data size (rows,columns) (25000, 197)\n",
      "\n",
      "Key error [price]: No price-column in test-data\n",
      "['dummy', 'Driving_License', 'Previously_Insured', 'Vehicle_Damage', 'Region_Code_0', 'Region_Code_1', 'Region_Code_2', 'Region_Code_3', 'Region_Code_4', 'Region_Code_5', 'Region_Code_6', 'Region_Code_7', 'Region_Code_8', 'Region_Code_9', 'Region_Code_10', 'Region_Code_11', 'Region_Code_12', 'Region_Code_13', 'Region_Code_14', 'Region_Code_15', 'Region_Code_16', 'Region_Code_17', 'Region_Code_18', 'Region_Code_19', 'Region_Code_20', 'Region_Code_21', 'Region_Code_22', 'Region_Code_23', 'Region_Code_24', 'Region_Code_25', 'Region_Code_26', 'Region_Code_27', 'Region_Code_28', 'Region_Code_29', 'Region_Code_30', 'Region_Code_31', 'Region_Code_32', 'Region_Code_33', 'Region_Code_34', 'Region_Code_35', 'Region_Code_36', 'Region_Code_37', 'Region_Code_38', 'Region_Code_39', 'Region_Code_40', 'Region_Code_41', 'Region_Code_42', 'Region_Code_43', 'Region_Code_44', 'Region_Code_45', 'Region_Code_46', 'Region_Code_47', 'Region_Code_48', 'Region_Code_49', 'Region_Code_50', 'Region_Code_51', 'Region_Code_52', 'Vehicle_Age_0', 'Vehicle_Age_1', 'Vehicle_Age_2', 'Policy_Sales_Channel_1', 'Policy_Sales_Channel_2', 'Policy_Sales_Channel_3', 'Policy_Sales_Channel_4', 'Policy_Sales_Channel_7', 'Policy_Sales_Channel_8', 'Policy_Sales_Channel_9', 'Policy_Sales_Channel_10', 'Policy_Sales_Channel_11', 'Policy_Sales_Channel_12', 'Policy_Sales_Channel_13', 'Policy_Sales_Channel_14', 'Policy_Sales_Channel_15', 'Policy_Sales_Channel_16', 'Policy_Sales_Channel_17', 'Policy_Sales_Channel_18', 'Policy_Sales_Channel_19', 'Policy_Sales_Channel_20', 'Policy_Sales_Channel_21', 'Policy_Sales_Channel_22', 'Policy_Sales_Channel_23', 'Policy_Sales_Channel_24', 'Policy_Sales_Channel_25', 'Policy_Sales_Channel_26', 'Policy_Sales_Channel_27', 'Policy_Sales_Channel_28', 'Policy_Sales_Channel_29', 'Policy_Sales_Channel_30', 'Policy_Sales_Channel_31', 'Policy_Sales_Channel_32', 'Policy_Sales_Channel_35', 'Policy_Sales_Channel_36', 'Policy_Sales_Channel_37', 'Policy_Sales_Channel_38', 'Policy_Sales_Channel_39', 'Policy_Sales_Channel_40', 'Policy_Sales_Channel_42', 'Policy_Sales_Channel_43', 'Policy_Sales_Channel_44', 'Policy_Sales_Channel_45', 'Policy_Sales_Channel_46', 'Policy_Sales_Channel_47', 'Policy_Sales_Channel_48', 'Policy_Sales_Channel_49', 'Policy_Sales_Channel_50', 'Policy_Sales_Channel_51', 'Policy_Sales_Channel_52', 'Policy_Sales_Channel_53', 'Policy_Sales_Channel_54', 'Policy_Sales_Channel_55', 'Policy_Sales_Channel_56', 'Policy_Sales_Channel_57', 'Policy_Sales_Channel_58', 'Policy_Sales_Channel_59', 'Policy_Sales_Channel_60', 'Policy_Sales_Channel_61', 'Policy_Sales_Channel_62', 'Policy_Sales_Channel_63', 'Policy_Sales_Channel_64', 'Policy_Sales_Channel_65', 'Policy_Sales_Channel_66', 'Policy_Sales_Channel_68', 'Policy_Sales_Channel_69', 'Policy_Sales_Channel_71', 'Policy_Sales_Channel_73', 'Policy_Sales_Channel_78', 'Policy_Sales_Channel_80', 'Policy_Sales_Channel_81', 'Policy_Sales_Channel_86', 'Policy_Sales_Channel_87', 'Policy_Sales_Channel_88', 'Policy_Sales_Channel_89', 'Policy_Sales_Channel_90', 'Policy_Sales_Channel_91', 'Policy_Sales_Channel_92', 'Policy_Sales_Channel_93', 'Policy_Sales_Channel_94', 'Policy_Sales_Channel_95', 'Policy_Sales_Channel_96', 'Policy_Sales_Channel_97', 'Policy_Sales_Channel_98', 'Policy_Sales_Channel_100', 'Policy_Sales_Channel_101', 'Policy_Sales_Channel_103', 'Policy_Sales_Channel_106', 'Policy_Sales_Channel_107', 'Policy_Sales_Channel_108', 'Policy_Sales_Channel_109', 'Policy_Sales_Channel_110', 'Policy_Sales_Channel_111', 'Policy_Sales_Channel_113', 'Policy_Sales_Channel_114', 'Policy_Sales_Channel_115', 'Policy_Sales_Channel_116', 'Policy_Sales_Channel_118', 'Policy_Sales_Channel_119', 'Policy_Sales_Channel_120', 'Policy_Sales_Channel_121', 'Policy_Sales_Channel_122', 'Policy_Sales_Channel_123', 'Policy_Sales_Channel_124', 'Policy_Sales_Channel_125', 'Policy_Sales_Channel_126', 'Policy_Sales_Channel_127', 'Policy_Sales_Channel_128', 'Policy_Sales_Channel_129', 'Policy_Sales_Channel_130', 'Policy_Sales_Channel_131', 'Policy_Sales_Channel_132', 'Policy_Sales_Channel_133', 'Policy_Sales_Channel_134', 'Policy_Sales_Channel_135', 'Policy_Sales_Channel_136', 'Policy_Sales_Channel_138', 'Policy_Sales_Channel_139', 'Policy_Sales_Channel_140', 'Policy_Sales_Channel_143', 'Policy_Sales_Channel_145', 'Policy_Sales_Channel_146', 'Policy_Sales_Channel_147', 'Policy_Sales_Channel_148', 'Policy_Sales_Channel_150', 'Policy_Sales_Channel_151', 'Policy_Sales_Channel_152', 'Policy_Sales_Channel_153', 'Policy_Sales_Channel_154', 'Policy_Sales_Channel_155', 'Policy_Sales_Channel_156', 'Policy_Sales_Channel_157', 'Policy_Sales_Channel_158', 'Policy_Sales_Channel_159', 'Policy_Sales_Channel_160', 'Policy_Sales_Channel_163']\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# do major feature engineering - 0 | 1\n",
    "doengr = 1\n",
    "donormalize = 1\n",
    "\n",
    "# Full Train\n",
    "rawdata = 'kaggle/IA2-train.csv'\n",
    "dataframet = pd.read_csv(rawdata)\n",
    "rawdata = 'kaggle/IA2-dev.csv'\n",
    "dataframev = pd.read_csv(rawdata)\n",
    "dataframe_combo = pd.concat([dataframet, dataframev])\n",
    "dataframe_combo.to_csv('kaggle/IA2_combo.csv', index=False)\n",
    "rawdata = 'kaggle/IA2_combo.csv'\n",
    "traindata, train_id = preprocess(rawdata, donormalize=donormalize, istrain=1,\n",
    "                                 traininfo=None, doengr=doengr)\n",
    "\n",
    "\n",
    "# View final data entering the model.\n",
    "# print(traindata['X'])\n",
    "\n",
    "# Dev\n",
    "rawdata = 'kaggle/IA2-dev.csv'\n",
    "devdata, dev_id = preprocess(rawdata, donormalize=donormalize, istrain=0,\n",
    "                             traininfo=traindata, doengr=doengr)\n",
    "\n",
    "# Test\n",
    "rawdata = 'kaggle/IA2-test.csv'\n",
    "testdata, test_id = preprocess(rawdata, donormalize=donormalize, istrain=0,\n",
    "                             traininfo=traindata, doengr=doengr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*******L2: Model Selection************************\n",
      "(start): Regularization-scale:  0.00055\n",
      "k:     0, mse(train): 0.2501, mse(dev): 0.2416 | facc(train): 0.4941, facc(dev): 0.7316\n",
      "k:   500, mse(train): 0.1464, mse(dev): 0.1462 | facc(train): 0.7982, facc(dev): 0.8008\n",
      "k:  1000, mse(train): 0.1453, mse(dev): 0.1451 | facc(train): 0.7981, facc(dev): 0.7997\n",
      "k:  1500, mse(train): 0.1448, mse(dev): 0.1447 | facc(train): 0.7984, facc(dev): 0.8000\n",
      "k:  2000, mse(train): 0.1446, mse(dev): 0.1444 | facc(train): 0.7984, facc(dev): 0.7999\n",
      "k:  2500, mse(train): 0.1444, mse(dev): 0.1442 | facc(train): 0.7985, facc(dev): 0.8000\n",
      "k:  3000, mse(train): 0.1443, mse(dev): 0.1441 | facc(train): 0.7986, facc(dev): 0.7999\n",
      "k:  3500, mse(train): 0.1442, mse(dev): 0.1439 | facc(train): 0.7984, facc(dev): 0.7998\n",
      "k:  4000, mse(train): 0.1441, mse(dev): 0.1439 | facc(train): 0.7985, facc(dev): 0.8000\n",
      "k:  4500, mse(train): 0.1441, mse(dev): 0.1438 | facc(train): 0.7986, facc(dev): 0.8001\n",
      "k:  5000, mse(train): 0.1440, mse(dev): 0.1437 | facc(train): 0.7988, facc(dev): 0.8008\n",
      "k:  5500, mse(train): 0.1439, mse(dev): 0.1437 | facc(train): 0.7989, facc(dev): 0.8008\n",
      "k:  6000, mse(train): 0.1439, mse(dev): 0.1436 | facc(train): 0.7989, facc(dev): 0.8007\n",
      "k:  6500, mse(train): 0.1439, mse(dev): 0.1436 | facc(train): 0.7989, facc(dev): 0.8006\n",
      "k:  7000, mse(train): 0.1438, mse(dev): 0.1435 | facc(train): 0.7993, facc(dev): 0.8010\n",
      "k:  7500, mse(train): 0.1438, mse(dev): 0.1435 | facc(train): 0.7993, facc(dev): 0.8010\n",
      "k:  8000, mse(train): 0.1438, mse(dev): 0.1435 | facc(train): 0.7993, facc(dev): 0.8011\n",
      "k:  8500, mse(train): 0.1437, mse(dev): 0.1435 | facc(train): 0.7993, facc(dev): 0.8011\n",
      "MSE (Train): 0.1437 | (Validation): 0.1434\n",
      "Class Accuracy (Train): 0.7994 | (Validation): 0.8011\n",
      "Model Sparsity: 84\n",
      "Final Learned Weights\n",
      "Features (Top-5) with largest weight magnitude\n",
      "['Previously_Insured', 'Vehicle_Damage', 'dummy', 'Policy_Sales_Channel_160', 'Policy_Sales_Channel_152', 'Region_Code_0', 'Region_Code_22', 'Policy_Sales_Channel_151', 'Region_Code_6', 'Policy_Sales_Channel_163']\n",
      "[-3.4706 2.0771 -1.4641 -1.4571 -0.6527 -0.6011 -0.5820 -0.5684 0.5294\n",
      " 0.5279]\n",
      "(end): ----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEV: Model Training and Selection\n",
    "\n",
    "# - max. number of iterations (fixed) - epochs\n",
    "epochs = int(9e3) # early-stoppng is key here\n",
    "\n",
    "# - learning-rate (step-size) selection set\n",
    "# lrs =  [5e-3, 1e-2, 2e-2, 0.1, 0.5]\n",
    "# learning rate\n",
    "stepsize = 1e-1\n",
    "\n",
    "# - regularization scale size selection set\n",
    "# lregs = [1e-3, 2e-3, 5e-3, 1e-2] # ... 1e-1, 1, 1e1, 1e2, 1e3]\n",
    "lregs = [0.00055] #[1e-4, 5e-4, 1e-3]\n",
    "# regsize = 0.01 # 1e-1 to 1e-2 to 1e-3\n",
    "\n",
    "# - random weight initialization\n",
    "W = np.random.uniform(0, 0.01, (traindata['cols'], 1))\n",
    "W[0] = np.zeros(shape=(1, 1))\n",
    "\n",
    "# Turns out lists and dicts are passed by ref. in python.\n",
    "# They behave as global variables, modified in function they are passed to.\n",
    "\n",
    "# model's number of largest weighted features\n",
    "bigks = 10\n",
    "\n",
    "# list to hold all models\n",
    "model_sels = []\n",
    "\n",
    "# regularization rate\n",
    "# regtype = 1\n",
    "regtype = 2\n",
    "# regtype = 3\n",
    "# regtype = 0\n",
    "\n",
    "# for stepsize in lrs:\n",
    "for regsize in lregs:\n",
    "\n",
    "    print(f'\\n*******L{regtype}: Model Selection************************')\n",
    "    print('(start): Regularization-scale: ', regsize)\n",
    "    # print(W.T) # to debug muatbility\n",
    "\n",
    "    # - modeldict: data structure that holds details of the trained model\n",
    "    modeldict = {'W': W.copy(), 'stepsize': stepsize,\n",
    "                 'reg_type': regtype, 'reg_size': regsize, 'epochs': epochs,\n",
    "                 'cols': traindata['cols'],\n",
    "                 'normalize': traindata['scalers'],\n",
    "                 'mse_train': None, 'mse_dev': None,\n",
    "                 'facc_train': None, 'facc_dev': None,\n",
    "                 'sparsity': None, 'bigk': bigks, 'WBigK': None, 'WBigK_feats': None\n",
    "                 }\n",
    "\n",
    "    # - train: iterative line search (full batch)\n",
    "    batchgd(modeldict, stdlogistic, traindata, devdata)\n",
    "\n",
    "    model_sels.append(modeldict)\n",
    "\n",
    "    if np.isfinite(modeldict['mse_train'][-1]):\n",
    "        print(f\"MSE (Train): {modeldict['mse_train'][-1]:2.4f} | \"\n",
    "              f\"(Validation): {modeldict['mse_dev'][-1]:2.4f}\")\n",
    "        print(f\"Class Accuracy (Train): {modeldict['facc_train'][-1]:2.4f} | \"\n",
    "              f\"(Validation): {modeldict['facc_dev'][-1]:2.4f}\")\n",
    "\n",
    "        # print(W.T)\n",
    "        print(f\"Model Sparsity: {modeldict['sparsity']}\")\n",
    "        print('Final Learned Weights')\n",
    "        # print((modeldict['W']).T)\n",
    "        # Print top 5 weighted features\n",
    "        print(\"Features (Top-5) with largest weight magnitude\")\n",
    "        print(modeldict['WBigK_feats'].tolist())\n",
    "        wbigk_str = np.array2string(modeldict['WBigK'].flatten(),\n",
    "                                    formatter={'float_kind': '{0:2.4f}'.format})\n",
    "        print(wbigk_str)\n",
    "        print('(end): ----\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction INFERENCE\n",
    "from src.infer_models import infer\n",
    "from src.archs_models import stdlogistic\n",
    "\n",
    "for mdl in model_sels:\n",
    "  Yhat_test = infer(stdlogistic, mdl, testdata)\n",
    "  test_result = {'ID': test_id, 'Response': Yhat_test.flatten()}\n",
    "  dftest = pd.DataFrame(data=test_result)\n",
    "  dftest.to_csv(f\"kaggle/PA2_preds_oas_L{mdl['reg_type']}_{mdl['reg_size']}_{mdl['epochs']}.csv\", index=False)\n",
    "\n",
    "\n",
    "# -- gender kept 10000 -> gave higher train accuracy\n",
    "# -- gender not kept 10000 -> gave higher train accuracy than gender kept with 1e-4 > 1e-3\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4960223bc976db2175b76fe2ad494d75385dee2a49d18ebaeb4703041365e4ee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('oas': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
